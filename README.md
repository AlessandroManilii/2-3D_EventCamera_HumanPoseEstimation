# 3D Human Pose Estimation based on Convolutional Neural Network and Event-based cameras: a proof of concept on a DHP19 dataset

Human pose estimation is one of the main topics in Computer vision and Deep Learning fields. This repository describes the process of estimating human’s limbs positions using data from event cameras.

***Dataset***

The dataset used is Dynamic Vision Sensor (DVS) 3D Human Pose Dataset, in which 4 synchronized DVS cameras are used to record 33 specific movements from 17 different subjects while the Vicon motion capture system is used to generate position markers in 3D space in order to get groundtruth. More information and descriptions are available on the website https://sites.google.com/view/dhp19/home, with a section for download.

***Data preprocessing***

To preprocess DVS and Vicon data were followed steps described and implemented in https://github.com/SensorsINI/DHP19/tree/master/generate_DHP19 in which DVS frames are generated by accumulating a fixed number of events. Label positions were generated knowing the initial and final event timestamps for the DVS-frame and calculating average position in that time window.

## Training & Testing 

The approach used is the same described in *E. Calabrese, G. Taverni, C. Awai Easthope, S. Skriabine, F. Corradi, L. Longinotti, K. Eng, and T. Delbruck, “DHP19: Dynamic
vision sensor 3D human pose dataset,” in IEEE Conf. Comput. Vis. Pattern Recog. Workshops (CVPRW), 2019*.
The convolutional neural network used to estimate the human pose is implemented according to the architecture described in the above mentioned paper.

Training can be executed through *training_with_data_generator.py*.

For testing purpouses two variants are presented:

- *testing_without_conf.py* 
- *testing_with_conf.py* in which can be set a confidence threshold on predicted positions probability.
