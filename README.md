## 2/3D human pose estimation from event-camera based dataset

Human pose estimation is one of the main topics in Computer vision and Deep Learning fields. This repository describes the process of estimating human’s limbs positions using data from event camera.

***Dataset***

The dataset used is Dynamic Vision Sensor (DVS) 3D Human Pose Dataset in which 4 synchronized DVS cameras are used to record 33 specific movements from 17 differents subjects while Vicon motion capture system is used to generate marker positions in 3D space in order to get groundtruth. More info and description are available on website https://sites.google.com/view/dhp19/home, with a section for download.

***Data preprocessing***

To preprocess DVS and Vicon data use steps described and implemented in https://github.com/SensorsINI/DHP19/tree/master/generate_DHP19 in which DVS frames are generated by accumulating a fixed number of events while label positions are generated knowing the DVS-frame initial and final event timestamps and calculating average position in that time window.

# Training & Testing 

The approach used is the same described in *E. Calabrese, G. Taverni, C. Awai Easthope, S. Skriabine, F. Corradi, L. Longinotti, K. Eng, and T. Delbruck, “DHP19: Dynamic
vision sensor 3D human pose dataset,” in IEEE Conf. Comput. Vis. Pattern Recog. Workshops (CVPRW), 2019*.
The convolutional neural network used for pose estimation is implemented according to the architecture described in the above mentioned paper.

Training can be executed through *training_with_datagenerator.py*.

For testing purpouse two variants are presented:

- *testing_without_conf* 
- *testing_with_conf* in which a confidence threshold can be set on predicted positions probability.
